{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"ESCAPE-NA1.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imparied = (df[\"moca\"] < 23).sum()\n",
    "\n",
    "not_imparied = (df[\"moca\"] >= 23).sum()\n",
    "\n",
    "\n",
    "print (\"MoCA < 23 where they are imparied :\", imparied)\n",
    "print (\"Moca >= 23 where they are not imparied:\", not_imparied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the coloumns that we do not want \n",
    "\n",
    "\n",
    "df = df.drop(\"test_dice_score\", axis = 1) \n",
    "df = df.drop(\"train_dice_score\", axis = 1) \n",
    "df = df.drop(\"ecrcl_BL\", axis = 1) \n",
    "df = df.drop(\"ena1_id\", axis = 1) \n",
    "df = df.drop(\"hx_smok.1\", axis = 1) \n",
    "df = df.drop(\"hx_diab.1\", axis = 1) \n",
    "df = df.drop(\"site_enrolment\", axis = 1) \n",
    "df = df.drop(\"hx_anticoag\", axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the coloumn names \n",
    "\n",
    "df.columns = (df.columns.str.strip().str.lower().str.replace(r'[^a-z0-9]+', '_', regex=True).str.replace(r'_+$', '', regex=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the region coloumn cause the naming of Canada is not correct \n",
    "\n",
    "if 'region' in df.columns: \n",
    "    \n",
    "    df['region'] = df['region'].replace({'Canadaa' : 'Canada'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the MoCA scores to Numeric and drop the rows without a MoCA score\n",
    "\n",
    "df[\"moca\"] = pd.to_numeric(df[\"moca\"], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"moca\"])\n",
    "\n",
    "# Create the binary target where 1 = cogntive decline and 0 = no decline \n",
    "df[\"target\"] = (df[\"moca\"] < 23).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    \"region\",\n",
    "    \"country\",\n",
    "    \"sex\",\n",
    "    \"race\",\n",
    "    \"ethnic\",\n",
    "    \"rx_weight\",\n",
    "    \"age_calc\",\n",
    "    \"hx_diab\",\n",
    "    \"hx_smok\",\n",
    "    \"hgb_bl\",\n",
    "    \"plt_bl\",\n",
    "    \"hct_bl\",\n",
    "    \"ptt_bl\",\n",
    "    \"inr_bl\",\n",
    "    \"glc_bl\",\n",
    "    \"na_bl\",\n",
    "    \"k_bl\",\n",
    "    \"cl_bl\",\n",
    "    \"hco3_bl\",\n",
    "    \"creat_bl\",\n",
    "    \"egfr_bl\",\n",
    "    \"hx_cadihd\",\n",
    "    \"hx_chf\",\n",
    "    \"hx_recestrk\",\n",
    "    \"hx_paststrk\",\n",
    "    \"hx_ich\",\n",
    "    \"hx_cnstraum\",\n",
    "    \"hx_majsurg\",\n",
    "    \"hx_pvd\",\n",
    "    \"hx_crf\",\n",
    "    \"hx_highchol\",\n",
    "    \"hx_afib\",\n",
    "    \"hx_htn\",\n",
    "\n",
    "]\n",
    "\n",
    "X = df[feature_columns]\n",
    "\n",
    "Y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_columns = [c for c in feature_columns if c not in numeric_columns]\n",
    "\n",
    "print(\"Numeric features:\", numeric_columns)\n",
    "print(\"Categorical features\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test \n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    test_size = 0.2,\n",
    "    random_state = 42,\n",
    "    stratify = Y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Numeric columns, replaces the missing values with the median \n",
    "transformer_numeric = Pipeline(steps = [(\"imputer\", SimpleImputer(strategy = \"median\")),(\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "# Categorical columns, replaces the missing values with the most common value\n",
    "transformer_categorical = Pipeline(steps = [(\"imputer\", SimpleImputer(strategy =\"most_frequent\")), (\"onehot\", OneHotEncoder( drop=\"first\", handle_unknown = \"ignore\"))]\n",
    ")\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers = [\n",
    "        (\"num\", transformer_numeric, numeric_columns),\n",
    "        (\"cat\", transformer_categorical, categorical_columns)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_pipeline = Pipeline([(\"prep\", preprocess)])\n",
    "\n",
    "temp_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "categorical_pipline = temp_pipeline.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "onehot = categorical_pipline.named_steps[\"onehot\"]\n",
    "\n",
    "features_ohe = list(onehot.get_feature_names_out(categorical_columns))\n",
    "\n",
    "features_all = numeric_columns + features_ohe\n",
    "\n",
    "\n",
    "print(\"Cohort Characteristics\")\n",
    "\n",
    "print(f\"Total patients: {len(df)}\")\n",
    "print(f\"Training set: {len(X_train)}\")\n",
    "print(f\"Test set: {len(X_test)}\")\n",
    "\n",
    "print(f\"Cognitive impairment rate: {Y.mean():.1%}\")\n",
    "print(f\"Total features after encoding done: {len(features_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 Model \n",
    "\n",
    "cs = np.logspace(-3, 2, 15)\n",
    "\n",
    "l1_model = LogisticRegressionCV(\n",
    "    Cs = cs, cv = 5, penalty = \"l1\", solver = \"saga\",\n",
    "    scoring = \"roc_auc\", max_iter = 5000, n_jobs = -1, refit = True\n",
    ")\n",
    "\n",
    "l1_pipe = Pipeline([(\"prep\", clone(preprocess)), (\"model\", l1_model)])\n",
    "l1_pipe.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "l1_predict_y = l1_pipe.predict(X_test)\n",
    "l1_proba_y = l1_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "l1_acc = accuracy_score(Y_test, l1_predict_y)\n",
    "l1_auc = roc_auc_score(Y_test, l1_proba_y)\n",
    "\n",
    "print (\"L1 Model\")\n",
    "print(f\"Accuracy: {l1_acc:.3f}\")\n",
    "print(f\"ROC AUC: {l1_auc:.3f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l1_coefs = l1_pipe.named_steps[\"model\"].coef_.ravel()\n",
    "epsilon = 1e-6\n",
    "l1_n_selected = np.sum(np.abs(l1_coefs) > epsilon)\n",
    "\n",
    "print(f\"Number of selected features: {l1_n_selected} / {len(features_all)}\")\n",
    "\n",
    "\n",
    "# Sparse predictors \n",
    "\n",
    "l1_coef_df = pd.DataFrame({ \"feature\": features_all, \"coef\": l1_coefs, \"abs_coef\": np.abs(l1_coefs)})\n",
    "\n",
    "\n",
    "\n",
    "l1_sparse_df = l1_coef_df[l1_coef_df[\"abs_coef\"] > epsilon].sort_values(\"abs_coef\", ascending = False )\n",
    "\n",
    "print(f\"Sparse predictors: {len(l1_sparse_df)} / {len(features_all)}\")\n",
    "\n",
    "print(\"\\nTop 20 Sparse Predictors:\")\n",
    "print(l1_sparse_df[['feature', 'coef', 'abs_coef']].head(20).to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elastic net Model \n",
    "\n",
    "\n",
    "en_model = LogisticRegressionCV(\n",
    "    Cs = cs, cv = 5, penalty= \"elasticnet\", solver= \"saga\", l1_ratios = [0.3, 0.5, 0.7], scoring = \"roc_auc\",\n",
    "    max_iter= 5000, n_jobs=-1, refit = True\n",
    ")\n",
    "\n",
    "en_pipe = Pipeline([(\"prep\", clone(preprocess)),  (\"model\", en_model)])\n",
    "en_pipe.fit(X_train, Y_train)\n",
    "\n",
    "en_predict_y = en_pipe.predict(X_test)\n",
    "en_proba_y = en_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "en_acc = accuracy_score(Y_test, en_predict_y)\n",
    "en_auc = roc_auc_score(Y_test, en_proba_y)\n",
    "\n",
    "print(f\"Accuracy: {en_acc:.3f}\")\n",
    "print(f\"ROC AUC: {en_auc:.3f}\")\n",
    "\n",
    "print(f\"Best l1 ratio: {en_pipe.named_steps['model'].l1_ratio_[0]:.2f}\")\n",
    "\n",
    "\n",
    "en_coefs = en_pipe.named_steps[\"model\"].coef_.ravel()\n",
    "en_n_selected = np.sum(np.abs(en_coefs) > epsilon)\n",
    "\n",
    "print(f\"Number of selected features: {en_n_selected} /{len(features_all)}\")\n",
    "\n",
    "\n",
    "# Sparse predictors \n",
    "en_coef_df = pd.DataFrame({\n",
    "\n",
    "    \"feature\": features_all, \"coef\": en_coefs, \"abs_coef\": np.abs(en_coefs)\n",
    "\n",
    "\n",
    "})\n",
    "\n",
    "en_sparse_df = en_coef_df[en_coef_df[\"abs_coef\"] > epsilon].sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "print(f\"Sparse predictors: {len(en_sparse_df)}/ {len(features_all)}\")\n",
    "\n",
    "\n",
    "print(\"\\nTop 20 sparse predictors:\")\n",
    "print(en_sparse_df[['feature', 'coef', 'abs_coef']].head(20).to_string(index=False))\n",
    "\n",
    "\n",
    "print (\"Elastic Net Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model \n",
    "\n",
    "print (\"Random Forest Model\")\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators= 500, max_depth = 10, min_samples_leaf= 10, min_samples_split= 20, max_features= 'sqrt'\n",
    "    , class_weight= 'balanced', random_state= 42, n_jobs = -1\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline([(\"prep\", clone(preprocess)), (\"model\", rf_model)])\n",
    "rf_pipe.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "rf_predict_y = rf_pipe.predict(X_test)\n",
    "rf_proba_y = rf_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "rf_acc = accuracy_score(Y_test, rf_predict_y)\n",
    "rf_auc = roc_auc_score(Y_test, rf_proba_y)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {rf_acc:.3f}\")\n",
    "print(f\"ROC AUC: {rf_auc:.3f}\")\n",
    "\n",
    "\n",
    "rf_importance = rf_pipe.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "# Feature importance, greater than 1% \n",
    "rf_n_important = np.sum(rf_importance > 0.01)\n",
    "print(f\"Number of important features (>1%): {rf_n_important}/{len(features_all)}\")\n",
    "\n",
    "\n",
    "# Sparse predictors \n",
    "rf_importance_df = pd.DataFrame({\n",
    "\n",
    "    \"feature\" : features_all,\n",
    "    \"importance\" : rf_importance }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "rf_important_df = rf_importance_df [ rf_importance_df[\"importance\"] > 0.01] \n",
    "print(f\"Important features: {len(rf_important_df)}/{len(features_all)}\")\n",
    "\n",
    "\n",
    "print(\"\\n Top 20 sparse predictors:\")\n",
    "print(rf_important_df.head(20).to_string(index=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comaprision \n",
    "\n",
    "df_comparision = pd.DataFrame({\n",
    "\n",
    "    'Model': ['L1 (Lasso', 'Elastic net', 'Random Forest'],\n",
    "    'Accuracy' : [l1_acc, en_acc, rf_acc],\n",
    "    'ROC AUC': [l1_auc, en_auc, rf_auc],\n",
    "    'n features selected': [l1_n_selected, en_n_selected, rf_n_important]\n",
    "\n",
    "})\n",
    "\n",
    "print(df_comparision.to_string(index = False))\n",
    "\n",
    "print(\"\\n Best model by ROC AUC:\", df_comparision.loc[df_comparision['ROC AUC'].idxmax(), 'Model'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap analysis \n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "n_bootstraps = 50 \n",
    "\n",
    "l1_selection = np.zeros(len(features_all))\n",
    "\n",
    "en_selection = np.zeros(len(features_all))\n",
    "\n",
    "rf_selection = np.zeros(len(features_all))\n",
    "\n",
    "\n",
    "for b in range(n_bootstraps):\n",
    "    idx = np.random.choice(len(X_train), size = len(X_train), replace= True)\n",
    "    X_boot = X_train.iloc[idx]\n",
    "    Y_boot = Y_train.iloc[idx]\n",
    "\n",
    "\n",
    "    # L1 model \n",
    "\n",
    "    l1_model_boot = LogisticRegressionCV(\n",
    "        Cs = cs, cv = 5, penalty = \"l1\", solver = \"saga\",\n",
    "        scoring = \"roc_auc\", max_iter = 5000, n_jobs = -1, refit = True\n",
    "    )\n",
    "\n",
    "    l1_pipe_boot = Pipeline([(\"prep\", clone(preprocess)), (\"model\", l1_model_boot)])\n",
    "    l1_pipe_boot.fit(X_boot, Y_boot)\n",
    "\n",
    "    l1_coefs_boot = l1_pipe_boot.named_steps[\"model\"].coef_.ravel()\n",
    "    l1_selection[np.where (np.abs(l1_coefs_boot) > epsilon)[0]] +=1\n",
    "\n",
    "\n",
    "\n",
    "    # Elastic net model \n",
    "    en_model_boot = LogisticRegressionCV(\n",
    "        Cs = cs, cv = 5, penalty= \"elasticnet\", solver= \"saga\", l1_ratios = [0.3, 0.5, 0.7], scoring = \"roc_auc\",\n",
    "        max_iter= 5000, n_jobs= -1, refit = True\n",
    "    )\n",
    "\n",
    "    en_pipe_boot = Pipeline([(\"prep\", clone(preprocess)),  (\"model\", en_model_boot)])\n",
    "    en_pipe_boot.fit(X_boot, Y_boot)\n",
    "    en_coefs_boot = en_pipe_boot.named_steps[\"model\"].coef_.ravel()\n",
    "\n",
    "    en_selection[np.where(np.abs(en_coefs_boot ) > epsilon)[0]] +=1\n",
    "\n",
    "\n",
    "\n",
    "    # Random Forest \n",
    "    rf_model_boot = RandomForestClassifier(\n",
    "        n_estimators= 500, max_depth = 10, min_samples_leaf= 10, min_samples_split= 20, \n",
    "        max_features= 'sqrt'\n",
    "        , class_weight= 'balanced', random_state= b, n_jobs =-1\n",
    "    )\n",
    "\n",
    "    rf_pipe_boot = Pipeline([(\"prep\", clone(preprocess)), (\"model\", rf_model_boot)])\n",
    "    rf_pipe_boot.fit(X_boot, Y_boot)\n",
    "\n",
    "    rf_importance_boot = rf_pipe_boot.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "    rf_selection[np.where(rf_importance_boot > 0.01) [0]] +=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stability_compare = pd.DataFrame({\n",
    "    'feature' : features_all,\n",
    "    'L1_freq' : l1_selection / n_bootstraps,\n",
    "    'Elastic_Net_freq': en_selection / n_bootstraps,\n",
    "    'Random_forest_freq': rf_selection /n_bootstraps\n",
    "\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "cons_threshold = 0.6 \n",
    "\n",
    "stability_compare['consensus'] = (\n",
    "\n",
    "    (stability_compare ['L1_freq'] >= cons_threshold).astype(int) + (stability_compare['Elastic_Net_freq'] >= cons_threshold).astype(int) + \n",
    "    (stability_compare['Random_forest_freq'] >= cons_threshold).astype(int)\n",
    ")\n",
    "\n",
    "\n",
    "stability_compare['average_freq'] = stability_compare[['L1_freq', 'Elastic_Net_freq', 'Random_forest_freq']].mean(axis=1)\n",
    "stability_compare = stability_compare.sort_values(['consensus', 'average_freq'], ascending = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Stable predictors\")\n",
    "print(f\"L1 stable features: {(stability_compare['L1_freq'] >= cons_threshold).sum()}\")\n",
    "print(f\"Elastic Net stable features: {(stability_compare['Elastic_Net_freq']  >= cons_threshold).sum()}\")\n",
    "print(f\"Random Forest stable features: {( stability_compare['Random_forest_freq'] >=  cons_threshold).sum()}\")\n",
    "\n",
    "\n",
    "print(f\" \\n Consensus features (that stable in two or more of the models): {(stability_compare['consensus'] >= 2).sum()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show just the top 20 consensus features \n",
    "\n",
    "consensus_features = stability_compare[stability_compare['consensus'] >= 2]\n",
    "\n",
    "print(\"Top 20 Consensus Features\")\n",
    "\n",
    "print(consensus_features[['feature', \"L1_freq\", \"Elastic_Net_freq\", \"Random_forest_freq\", \"consensus\"]].head(20).to_string(index = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all the 37 consensus features \n",
    "\n",
    "print(consensus_features[['feature', \"L1_freq\", \"Elastic_Net_freq\", \"Random_forest_freq\", \"consensus\"]].to_string(index = False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the features by consensus level \n",
    "\n",
    "universal_consensus = stability_compare[stability_compare['consensus'] == 3]\n",
    "print(\"Universal consensus (All three models)\")\n",
    "print(universal_consensus[['feature', 'L1_freq', 'Elastic_Net_freq', 'Random_forest_freq']].to_string(index = False))\n",
    "\n",
    "\n",
    "two_model_consensus = stability_compare[stability_compare['consensus'] == 2]\n",
    "print(\"2 Model Consensus\")\n",
    "print(two_model_consensus[['feature', 'L1_freq', 'Elastic_Net_freq', 'Random_forest_freq']].to_string(index = False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations \n",
    "\n",
    "top_n_features = 20\n",
    "\n",
    "top_features = consensus_features.head(top_n_features)\n",
    "\n",
    "data = top_features[['L1_freq', 'Elastic_Net_freq', 'Random_forest_freq']].T\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "sns.heatmap(\n",
    "    data,\n",
    "    xticklabels= top_features['feature'].values, \n",
    "    yticklabels= ['L1', 'Elastic Net', 'Random Forest'],\n",
    "    annot = True,\n",
    "    fmt = '.2f',\n",
    "    cmap = 'YlOrRd',\n",
    "    vmin = 0,\n",
    "    vmax=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Stability of Top 20 Consensus Predictors Across Models')\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Model\")\n",
    "\n",
    "plt.tight_layout(\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_n_features = 20\n",
    "\n",
    "top_features = consensus_features.head(top_n_features)\n",
    "\n",
    "data = top_features[['L1_freq', 'Elastic_Net_freq', 'Random_forest_freq']].values\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "sns.heatmap(\n",
    "    data,\n",
    "    xticklabels= ['L1', 'Elastic Net', 'Random Forest'],\n",
    "    yticklabels= top_features['feature'].values, \n",
    "    annot = True,\n",
    "    cmap = 'YlOrRd',\n",
    "    fmt = '.2f',\n",
    "    vmax=1,\n",
    "    vmin = 0,\n",
    "    ax = ax\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "plt.title('Stability of Top 20 Consensus Predictors Across Models')\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Model\")\n",
    "\n",
    "plt.tight_layout(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stability Heatmap for just the vascular features \n",
    "\n",
    "vascular_features = [\n",
    "    \"hx_afib\",\n",
    "    \"hx_htn\",\n",
    "    \"hx_highchol\",\n",
    "    \"hx_cadihd\",\n",
    "    \"hx_chf\",\n",
    "    \"hx_pvd\",\n",
    "    \"hx_crf\",\n",
    "    \"hx_recestrk\",\n",
    "    \"hx_paststrk\",\n",
    "]\n",
    "\n",
    "vascular_stability = stability_compare[\n",
    "    stability_compare[\"feature\"].isin(vascular_features)].copy()\n",
    "\n",
    "\n",
    "vascular_features_order = [\n",
    "    \"hx_afib\",\n",
    "    \"hx_htn\",\n",
    "    \"hx_highchol\",\n",
    "    \"hx_cadihd\",\n",
    "    \"hx_chf\",\n",
    "    \"hx_pvd\",\n",
    "    \"hx_crf\",\n",
    "    \"hx_recestrk\",\n",
    "    \"hx_paststrk\",\n",
    "]\n",
    "\n",
    "vascular_stability[\"feature\"] = pd.Categorical(vascular_stability[\"feature\"], categories= vascular_features_order, \n",
    "ordered = True)\n",
    "\n",
    "\n",
    "vascular_stability = vascular_stability.sort_values(\"feature\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "heatmap_data = vascular_stability[[\"L1_freq\", \"Elastic_Net_freq\", \"Random_forest_freq\"]].values\n",
    "\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    yticklabels=vascular_stability[\"feature\"].values,\n",
    "    xticklabels=[\"L1\", \"Elastic Net\", \"Random Forest\"],\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"YlOrRd\",\n",
    "    vmax=1,\n",
    "    vmin=0,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Stability of Vascular Comorbidities Across Models\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "\n",
    "# Performance by ROC AUC comparision\n",
    "axes[0].bar(['L1', 'Elastic Net', 'Random Forest'],\n",
    "\n",
    "            [l1_auc, en_auc, rf_auc],\n",
    "\n",
    "            color=['#2ecc71', '#3498db', '#e74c3c'])\n",
    "\n",
    "\n",
    "axes[0].set_ylabel('ROC AUC')\n",
    "axes[0].set_title('Model Performance: ROC AUC')\n",
    "\n",
    "axes[0].set_ylim([0.5, 1.0])\n",
    "axes[0].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Feature selection comparison \n",
    "axes[1].bar(['L1', 'Elastic Net', 'Random Forest'], [l1_n_selected, en_n_selected, rf_n_important], color=['#2ecc71', '#3498db', '#e74c3c'])\n",
    "\n",
    "axes[1].set_ylabel('Number of Features')\n",
    "axes[1].set_title('Feature Sparsity')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tbale of features before preprocessing \n",
    "\n",
    "domains_before_preprocess = {\n",
    "    \"Identifiers / metadata\": [ \"ena1_id\", \"site_enrolment\",\n",
    "    ],\n",
    "\n",
    "    \"Demographics\": [ \"age_calc\",\"sex\", \"race\", \"ethnic\", \"region\",\n",
    "        \"country\",  \"rx_weight\", \"moca\",\n",
    "\n",
    "    ],\n",
    "\n",
    "\n",
    "    \"Medical history\": [ \"hx_diab\", \"hx_diab.1\", \"hx_smok\", \"hx_smok.1\", \"hx_cadihd\", \"hx_chf\",\n",
    "        \"hx_recestrk\", \"hx_paststrk\", \"hx_ich\", \"hx_cnstraum\", \"hx_majsurg\",\n",
    "        \"hx_pvd\", \"hx_crf\", \"hx_highchol\", \"hx_afib\", \"hx_htn\",\n",
    "        \"hx_anticoag\",\n",
    "    \n",
    "    ],\n",
    "    \n",
    "    \"Baseline laboratory values\": [ \"hgb_BL\",\"plt_BL\", \"hct_BL\", \"ptt_BL\",\"inr_BL\", \"glc_BL\",\"na_BL\",\n",
    "        \"k_BL\", \"cl_BL\", \"hco3_BL\",\"creat_BL\", \"egfr_BL\", \"ecrcl_BL\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for domain, vars_list in domains_before_preprocess.items():\n",
    "    rows.append({\n",
    "        \"Domain\": domain,\n",
    "        \"Variables\": \", \".join(vars_list)\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_before_domains = pd.DataFrame(rows)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 4)) \n",
    "ax.axis('off')\n",
    "\n",
    "before_table = ax.table(\n",
    "    cellText=df_before_domains.values,\n",
    "    colLabels=df_before_domains.columns,\n",
    "    cellLoc='left',\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "\n",
    "before_table.auto_set_font_size(False)\n",
    "before_table.set_fontsize(10)\n",
    "\n",
    "\n",
    "before_table.auto_set_column_width(col = list(range(len( df_before_domains.columns ))))\n",
    "\n",
    "for (row, col), cell in before_table.get_celld().items():\n",
    "    if row == 0:\n",
    "        cell.set_text_props(weight='bold')\n",
    "        cell.set_facecolor('#f0f0f0')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table of features after preprocessing (features dropped, duplicate columns removed, etc)\n",
    "\n",
    "domains_after_preprocess = {\n",
    "    \"Demographics\": [\n",
    "        \"region\",\"country\", \"sex\", \"race\", \"ethnic\",\n",
    "        \"rx_weight\", \"age_calc\"\n",
    "    ],\n",
    "\n",
    "    \"Baseline laboratory values\": [\n",
    "        \"hgb_bl\", \"plt_bl\", \"hct_bl\",\"ptt_bl\", \"inr_bl\", \"glc_bl\", \"na_bl\", \"k_bl\", \"cl_bl\", \"hco3_bl\",\n",
    "        \"creat_bl\", \"egfr_bl\"\n",
    "    ],\n",
    "\n",
    "\n",
    "    \"Medical history\": [\n",
    "        \"hx_diab\", \"hx_smok\", \"hx_cadihd\",\"hx_chf\", \"hx_recestrk\", \"hx_paststrk\", \"hx_ich\",\n",
    "        \"hx_cnstraum\", \"hx_majsurg\", \"hx_pvd\", \"hx_crf\",\n",
    "        \"hx_highchol\",\"hx_afib\",  \"hx_htn\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "rows = []\n",
    "for domains_after_preprocess, vars_list in domains_after_preprocess.items():\n",
    "    rows.append({\n",
    "        \"Domain\": domains_after_preprocess,\n",
    "        \"Predictors\": \", \".join(vars_list)\n",
    "    })\n",
    "\n",
    "\n",
    "df_domains_after = pd.DataFrame(rows)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 3))\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "after_table = ax.table(\n",
    "    cellText= df_domains_after.values,\n",
    "    colLabels= df_domains_after.columns,\n",
    "\n",
    "    loc = 'center',\n",
    "    cellLoc = 'left',\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "after_table.auto_set_font_size(False)\n",
    "after_table.set_fontsize(10)\n",
    "after_table.auto_set_column_width(col= list( range(len( df_domains_after.columns))))\n",
    "\n",
    "\n",
    "for (row, col), cell in after_table.get_celld().items():\n",
    "\n",
    "    if row == 0:\n",
    "        cell.set_text_props(weight='bold')\n",
    "\n",
    "        cell.set_facecolor('#f0f0f0')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
